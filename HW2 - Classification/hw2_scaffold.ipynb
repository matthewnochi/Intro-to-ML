{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Predicting sentiment from product reviews\n",
                "\n",
                "The goal of this first notebook is to explore logistic regression and feature engineering with sklearn.\n",
                "\n",
                "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative. Specifically, you will:\n",
                "\n",
                "* Use a Pandas Dataframes to do feature engineering\n",
                "* Train a logistic regression model to predict the sentiment of product reviews.\n",
                "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
                "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
                "* Given a classifier, create a confusion matrix\n",
                "* Compare multiple logistic regression models.\n",
                "\n",
                "\n",
                "Copyright Â©2023 Emily Fox, Hunter Schafer, Valentina Staneva.  All rights reserved.  Permission is hereby granted to students registered for University of Washington CSE/STAT 416 for use solely during Spring Quarter 2024 for purposes of the course.  No other use, copying, distribution, or modification is permitted without prior written consent. Copyrights for third-party components of this work must be honored.  Instructors interested in reusing these course materials should contact the author.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import string\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.feature_extraction import DictVectorizer\n",
                "\n",
                "sns.set()\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data preparation\n",
                "\n",
                "We will use a dataset consisting of food product reviews on Amazon.com [source](http://jmcauley.ucsd.edu/data/amazon/).\n",
                "\n",
                "**NOTE**: Be sure to run every cell in the notebook! The `###SKIP` is for the autograder. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eproduct_id\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n      \u003cth\u003ereview\u003c/th\u003e\n      \u003cth\u003erating\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e4408\u003c/td\u003e\n      \u003ctd\u003eDoes increase milk supply\u003c/td\u003e\n      \u003ctd\u003eThis really helped to increase my milk supply....\u003c/td\u003e\n      \u003ctd\u003e3.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e4209\u003c/td\u003e\n      \u003ctd\u003eOne bad packet ruins the product!\u003c/td\u003e\n      \u003ctd\u003eI should have stayed with Idahoan brand. Poor ...\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e8623\u003c/td\u003e\n      \u003ctd\u003eCAULIFLOWER PASTA!?\u003c/td\u003e\n      \u003ctd\u003eAs the pasta cooked, I read the box to see wha...\u003c/td\u003e\n      \u003ctd\u003e4.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e9439\u003c/td\u003e\n      \u003ctd\u003eTasty and inexpensive\u003c/td\u003e\n      \u003ctd\u003eI really like this cereal. The flavor is sligh...\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e7110\u003c/td\u003e\n      \u003ctd\u003eI'm Confused\u003c/td\u003e\n      \u003ctd\u003eThe label on the bowl says 35 grams is in the ...\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "   product_id                            summary  \\\n0        4408          Does increase milk supply   \n1        4209  One bad packet ruins the product!   \n2        8623                CAULIFLOWER PASTA!?   \n3        9439              Tasty and inexpensive   \n4        7110                       I'm Confused   \n\n                                              review  rating  \n0  This really helped to increase my milk supply....     3.0  \n1  I should have stayed with Idahoan brand. Poor ...     1.0  \n2  As the pasta cooked, I read the box to see wha...     4.0  \n3  I really like this cereal. The flavor is sligh...     5.0  \n4  The label on the bowl says 35 grams is in the ...     2.0  "
                    },
                    "execution_count": 131,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "### SKIP\n",
                "products = pd.read_csv('food_products.csv')\n",
                "\n",
                "# Set seed for the whole program\n",
                "np.random.seed(416)\n",
                "\n",
                "products.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Do not modify the below cell. It configures the autograder, which will award 0 points if it doesn't run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_load_data) ###"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Extract sentiments\n",
                "\n",
                "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment. Let's see how many of each rating we have."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "889"
                    },
                    "execution_count": 133,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "products = products[products['rating'] != 3].copy()\n",
                "\n",
                "len(products)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 134,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "\u003cAxes: title={'center': 'Number of reviews with a given rating'}, xlabel='rating', ylabel='Count'\u003e"
                    },
                    "execution_count": 134,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": "\u003cFigure size 640x480 with 1 Axes\u003e"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.title('Number of reviews with a given rating')\n",
                "sns.histplot(products['rating'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 135,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eproduct_id\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n      \u003cth\u003ereview\u003c/th\u003e\n      \u003cth\u003erating\u003c/th\u003e\n      \u003cth\u003esentiment\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e4209\u003c/td\u003e\n      \u003ctd\u003eOne bad packet ruins the product!\u003c/td\u003e\n      \u003ctd\u003eI should have stayed with Idahoan brand. Poor ...\u003c/td\u003e\n      \u003ctd\u003e1.0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e8623\u003c/td\u003e\n      \u003ctd\u003eCAULIFLOWER PASTA!?\u003c/td\u003e\n      \u003ctd\u003eAs the pasta cooked, I read the box to see wha...\u003c/td\u003e\n      \u003ctd\u003e4.0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e9439\u003c/td\u003e\n      \u003ctd\u003eTasty and inexpensive\u003c/td\u003e\n      \u003ctd\u003eI really like this cereal. The flavor is sligh...\u003c/td\u003e\n      \u003ctd\u003e5.0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e7110\u003c/td\u003e\n      \u003ctd\u003eI'm Confused\u003c/td\u003e\n      \u003ctd\u003eThe label on the bowl says 35 grams is in the ...\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e5\u003c/th\u003e\n      \u003ctd\u003e1373\u003c/td\u003e\n      \u003ctd\u003eFlat\u003c/td\u003e\n      \u003ctd\u003eDoesn't taste like ginger.  Thought it would s...\u003c/td\u003e\n      \u003ctd\u003e2.0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "   product_id                            summary  \\\n1        4209  One bad packet ruins the product!   \n2        8623                CAULIFLOWER PASTA!?   \n3        9439              Tasty and inexpensive   \n4        7110                       I'm Confused   \n5        1373                               Flat   \n\n                                              review  rating  sentiment  \n1  I should have stayed with Idahoan brand. Poor ...     1.0         -1  \n2  As the pasta cooked, I read the box to see wha...     4.0          1  \n3  I really like this cereal. The flavor is sligh...     5.0          1  \n4  The label on the bowl says 35 grams is in the ...     2.0         -1  \n5  Doesn't taste like ginger.  Thought it would s...     2.0         -1  "
                    },
                    "execution_count": 135,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating \u003e 3 else -1)\n",
                "products.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build the word count vector for each review"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us explore a specific example of a food product. We have information about the product, the review left, and both the rating that was given and the sentiment label we computed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Rating : 4.0 (Sentiment=1)\nSummary: It's PRIME-arily Lobster\nReview : if it's primarily made from lobster, what else is in there? I wonder. Primarily...Who uses a word like that on a food label? It's primarily delicious among other things, things we usually have no energy to talk about after eating a fine meal. I'm so full of primarily lobster bisque that I've been making and have come to be addicted to. NO! I will not share the recipe, because I am too full and don't feel like it. Primarily.\n"
                }
            ],
            "source": [
                "example_product = products.iloc[21]\n",
                "print(f\"Rating : {example_product['rating']} (Sentiment={example_product['sentiment']})\")\n",
                "print(\"Summary:\", example_product[\"summary\"])\n",
                "print(\"Review :\", example_product[\"review\"])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To work with the text data, we will need to turn it into a vector of word counts. In other words, we will be making a feature for every word that could possibly appear in the data, and the value for that feature for one example would be the number of times that word appears in that example. \n",
                "\n",
                "To accomplish this, we will need to do two data transformation:\n",
                "\n",
                "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
                "2. Transform the reviews into word-counts.\n",
                "\n",
                "\n",
                "\n",
                "\u003e **Aside**. In this assignment, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. \n",
                "\u003e \n",
                "\u003e If you are curious in learning how to handle these complexities in practice, you might be interested in  researching more about tokenization and NLP like [this page](https://towardsdatascience.com/tokenization-for-natural-language-processing-a179a891bad4) shows. Note that you do not need to do any of that stuff for this assignment.\n",
                "\n",
                "So first, we remove punctuation with the code in the next cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_punctuation(text):\n",
                "    \"\"\"\n",
                "    Remove any punctuation in text. Python has a default set of \n",
                "    punctuation marks, stored in string.punctuation, that contains\n",
                "    !\"#$%\u0026'()*+, -./:;\u003c=\u003e?@[\\]^_`{|}~\n",
                "    \"\"\"\n",
                "    if type(text) is str:\n",
                "        return text.translate(str.maketrans('', '', string.punctuation))\n",
                "    else:\n",
                "        return ''\n",
                "    \n",
                "products['review_clean'] = products['review'].apply(remove_punctuation)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we use scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to get counts for each word. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e0000\u003c/th\u003e\n      \u003cth\u003e002\u003c/th\u003e\n      \u003cth\u003e004\u003c/th\u003e\n      \u003cth\u003e004oz\u003c/th\u003e\n      \u003cth\u003e012months\u003c/th\u003e\n      \u003cth\u003e032\u003c/th\u003e\n      \u003cth\u003e051\u003c/th\u003e\n      \u003cth\u003e08\u003c/th\u003e\n      \u003cth\u003e0f\u003c/th\u003e\n      \u003cth\u003e10\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003ezico1\u003c/th\u003e\n      \u003cth\u003ezico3\u003c/th\u003e\n      \u003cth\u003ezicos\u003c/th\u003e\n      \u003cth\u003ezillion\u003c/th\u003e\n      \u003cth\u003ezinger\u003c/th\u003e\n      \u003cth\u003ezip\u003c/th\u003e\n      \u003cth\u003eziplock\u003c/th\u003e\n      \u003cth\u003esentiment\u003c/th\u003e\n      \u003cth\u003ereview_clean\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n      \u003ctd\u003eI should have stayed with Idahoan brand Poor B...\u003c/td\u003e\n      \u003ctd\u003eOne bad packet ruins the product!\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003eAs the pasta cooked I read the box to see what...\u003c/td\u003e\n      \u003ctd\u003eCAULIFLOWER PASTA!?\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003eI really like this cereal The flavor is slight...\u003c/td\u003e\n      \u003ctd\u003eTasty and inexpensive\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n      \u003ctd\u003eThe label on the bowl says 35 grams is in the ...\u003c/td\u003e\n      \u003ctd\u003eI'm Confused\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e5\u003c/th\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n      \u003ctd\u003eDoesnt taste like ginger  Thought it would sav...\u003c/td\u003e\n      \u003ctd\u003eFlat\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e5 rows Ã 7628 columns\u003c/p\u003e\n\u003c/div\u003e",
                        "text/plain": "   0000  002  004  004oz  012months  032  051  08  0f  10  ...  zico1  zico3  \\\n1     0    0    0      0          0    0    0   0   0   0  ...      0      0   \n2     0    0    0      0          0    0    0   0   0   0  ...      0      0   \n3     0    0    0      0          0    0    0   0   0   0  ...      0      0   \n4     0    0    0      0          0    0    0   0   0   0  ...      0      0   \n5     0    0    0      0          0    0    0   0   0   0  ...      0      0   \n\n   zicos  zillion  zinger  zip  ziplock  sentiment  \\\n1      0        0       0    0        0         -1   \n2      0        0       0    0        0          1   \n3      0        0       0    0        0          1   \n4      0        0       0    0        0         -1   \n5      0        0       0    0        0         -1   \n\n                                        review_clean  \\\n1  I should have stayed with Idahoan brand Poor B...   \n2  As the pasta cooked I read the box to see what...   \n3  I really like this cereal The flavor is slight...   \n4  The label on the bowl says 35 grams is in the ...   \n5  Doesnt taste like ginger  Thought it would sav...   \n\n                             summary  \n1  One bad packet ruins the product!  \n2                CAULIFLOWER PASTA!?  \n3              Tasty and inexpensive  \n4                       I'm Confused  \n5                               Flat  \n\n[5 rows x 7628 columns]"
                    },
                    "execution_count": 138,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Make counts\n",
                "vectorizer = CountVectorizer()\n",
                "count_matrix = vectorizer.fit_transform(products['review_clean'])\n",
                "\n",
                "# Get the feature names (e.g., one per word)\n",
                "features = vectorizer.get_feature_names_out()\n",
                "\n",
                "# Make a new DataFrame with the counts information\n",
                "product_data = pd.DataFrame(count_matrix.toarray(),\n",
                "        index=products.index,\n",
                "        columns=features)\n",
                "\n",
                "# Add the old columns to our new DataFrame. \n",
                "# We won't use review_clean and the summary in our model, but we will keep\n",
                "# them to look at later.\n",
                "product_data['sentiment'] = products['sentiment']\n",
                "product_data['review_clean'] = products['review_clean']  \n",
                "product_data['summary'] = products['summary']\n",
                "\n",
                "product_data.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have now created a lot of features to work with! Note that in the table above, we will have one feature for each word that appeared in the data and the value for that feature is the count of that word in that review. So for example, if review 5 had the word \"dog\" in it 3 times, the value in row 5 and column \"dog\" would be 3.\n",
                "\n",
                "---\n",
                "\n",
                "\n",
                "\n",
                "## Split data into training, validation and test sets."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's perform a train/validation/test split with 80% of the data in the training set, 10% of the data in the validation set, 10% test. Note that we use `random_state=3` so that everyone gets the same result."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 139,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data, test_and_validation_data = train_test_split(product_data, test_size=0.2, random_state=3)\n",
                "validation_data, test_data = train_test_split(test_and_validation_data, test_size=0.5, random_state=3)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Baseline: Majority class prediction\n",
                "\n",
                "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points.\n",
                "\n",
                "To \"train\" the majority class classifier, you should simply find the most frequent target in the training data.\n",
                "\n",
                "### **Question 1:** Majority class classifier\n",
                "* Compute the most frequent label and store it in a variable called `majority_label`.\n",
                "* What is the validation accuracy of the majority class classifer. Store your result as a number between 0 and 1 in a variable called `majority_classifier_validation_accuracy`.\n",
                "  \n",
                "  *Hint:* pandas allows you to take the sum of a boolean series - true values are equal to 1, false values are equal 0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q1_majority_classifier) ###\n",
                "\n",
                "# TODO \"Train\" a majority class classifier and calculate its validation accuracy\n",
                "\n",
                "majority_label = train_data['sentiment'].mode()[0]\n",
                "predict_correct = (pd.Series([majority_label] * len(validation_data), index=validation_data.index) == validation_data['sentiment']).sum()\n",
                "majority_classifier_validation_accuracy = predict_correct / len(validation_data)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train a sentiment classifier with logistic regression\n",
                "\n",
                "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the columns representing word counts as features and the column **sentiment** as the target. We will set **no regularization penalty**, and set `random_state=1` to get the same answer as everyone else.\n",
                "\n",
                "You can see scikit-learn's documentation for LogisticRegression [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Note that the parameter for this class to control regularization is named `C` and it represents the inverse of the penalty strength. In other words $C = \\frac{1}{\\lambda}$. By default, $C=1.0$, which means if you don't specify `C` the model will have regularization. To have very little regularization, you have to specify `C` to be a very large number (corresponding to a very small $\\lambda$). (Note that technically, the better way to do this would be to pass in the parameter `penalty='none'` into the Logistic Regression model. However, in this assignment, for consistency across sub-parts, we use an L2 penalty with a large C value here.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cstyle\u003e#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `\u003ca\u003e` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n\u003c/style\u003e\u003cdiv id=\"sk-container-id-4\" class=\"sk-top-container\"\u003e\u003cdiv class=\"sk-text-repr-fallback\"\u003e\u003cpre\u003eLogisticRegression(C=1e+23, random_state=1)\u003c/pre\u003e\u003cb\u003eIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. \u003cbr /\u003eOn GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u003c/b\u003e\u003c/div\u003e\u003cdiv class=\"sk-container\" hidden\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-estimator fitted sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked\u003e\u003clabel for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\"\u003e\u0026nbsp;\u0026nbsp;LogisticRegression\u003ca class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\"\u003e?\u003cspan\u003eDocumentation for LogisticRegression\u003c/span\u003e\u003c/a\u003e\u003cspan class=\"sk-estimator-doc-link fitted\"\u003ei\u003cspan\u003eFitted\u003c/span\u003e\u003c/span\u003e\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content fitted\"\u003e\u003cpre\u003eLogisticRegression(C=1e+23, random_state=1)\u003c/pre\u003e\u003c/div\u003e \u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
                        "text/plain": "LogisticRegression(C=1e+23, random_state=1)"
                    },
                    "execution_count": 141,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Note: C = 1/Lambda. Setting C to a really high value is the same as setting lambda = 0\n",
                "sentiment_model = LogisticRegression(penalty='l2', C=1e23, random_state=1)\n",
                "sentiment_model.fit(train_data[features], train_data['sentiment'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's look at some of the coefficients and the corresponding words. The weights are stored in a `coef_` property: "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Smallest coefficient -5.987646623437152\nLargest coefficient: 11.015982338857766\n"
                }
            ],
            "source": [
                "coefficients = sentiment_model.coef_\n",
                "\n",
                "print('Smallest coefficient', coefficients.min())\n",
                "print('Largest coefficient:', coefficients.max())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Question 2:** Most Positive/Negative Word\n",
                "For the sentiment model we trained above, compute the word with the most negative weight and the word with the most positive weight.\n",
                "\n",
                "Store your results in the variables `most_negative_word` and `most_positive_word`.\n",
                "\n",
                "While you only need to write code to compute the most negative and most positive, we also recommend printing out the words with the highest magnitude coefficients to make sure they make sense.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 143,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q2_most_pos_neg_words) ###\n",
                "\n",
                "# TODO Find the most positive word and most negative word in the sentiment_model\n",
                "\n",
                "most_negative_word = features[coefficients.argmin()]\n",
                "most_positive_word = features[coefficients.argmax()]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Most negative word: not\nMost positive word: great\n"
                }
            ],
            "source": [
                "print('Most negative word:', most_negative_word)\n",
                "print('Most positive word:', most_positive_word)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Making predictions with logistic regression\n",
                "\n",
                "Now that a model is trained, we can make predictions on the **validation data**. In this first section, we will restrict the examples we are looking at to 3 examples in the validation dataset. We refer to this set of 3 examples as the **sample_data**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003esentiment\u003c/th\u003e\n      \u003cth\u003ereview_clean\u003c/th\u003e\n      \u003cth\u003esummary\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e493\u003c/th\u003e\n      \u003ctd\u003e-1\u003c/td\u003e\n      \u003ctd\u003eThe Chocolate Espresso flavor of the thinkThin...\u003c/td\u003e\n      \u003ctd\u003eNot a good taste\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e311\u003c/th\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003ehard candy with a smooth creamy milk taste i l...\u003c/td\u003e\n      \u003ctd\u003egreat taste\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e570\u003c/th\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003eWhen I was growing up split pea soup was a uni...\u003c/td\u003e\n      \u003ctd\u003eMore like split pea stew\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "     sentiment                                       review_clean  \\\n493         -1  The Chocolate Espresso flavor of the thinkThin...   \n311          1  hard candy with a smooth creamy milk taste i l...   \n570          1  When I was growing up split pea soup was a uni...   \n\n                      summary  \n493          Not a good taste  \n311               great taste  \n570  More like split pea stew  "
                    },
                    "execution_count": 145,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "sample_data = validation_data[8:11]\n",
                "sample_data[['sentiment', 'review_clean', 'summary']]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Predicting sentiment\n",
                "Let's start by predicting the probability of positive/negative sentiment of the 3 examples in the `sample_data`. The `predict_proba` method on the `LogisticRegression` class outputs a probability for each class possible.\n",
                "\n",
                "The output has one row for each example. Each row is an array of 2 numbers, the first is the predictor's prediction for the probability it is a negative sentiment example, and the second is the probability of it being a positive sentiment example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "  Prob Negative, Prob Positive\n[[1.00000000e+00 4.94811120e-17]\n [1.81738360e-07 9.99999818e-01]\n [1.00000000e+00 1.07223685e-11]]\n"
                }
            ],
            "source": [
                "print('  Prob Negative, Prob Positive')\n",
                "print(sentiment_model.predict_proba(sample_data[features]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are also able to predictions labels (i.e., $\\pm1$, not just probabilities) using the `predict` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Predicted labels\n[-1  1 -1]\n"
                }
            ],
            "source": [
                "print('Predicted labels')\n",
                "print(sentiment_model.predict(sample_data[features]))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Question 3:** Find the review predicted to be most positive (and negative)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now turn to examining the full **validation_data** dataset \u003cspan style=\"color:red\"\u003e(not sample_data)\u003c/span\u003e, , and use `sklearn` to form predictions on all of the data points for faster performance.\n",
                "\n",
                "Using the `sentiment_model`, find the review in the **validation_data** with the **highest probability** of being classified as a **positive review**. Also, find the review with the **highest probability** of being classified as a **negative review**. We refer to these as the \"most positive review\" and \"most negative review\" respectively. Store the `review_clean` column value for each of these rows in `most_positive_review` and `most_negative_review` variables respectively.\n",
                "\n",
                "If there is a tie for the most positive/negative reivew, you should always grab the one that appears *first* in the validation data.\n",
                "\n",
                "*Hint*: Once you know the index of the most positive/negative reviews, use the `.iloc[]` accessor on the DataFrame to get that row and find its `review_clean` value."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 148,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q3_most_positive_negative_review) ###\n",
                "\n",
                "# TODO Find the review_clean values for the most positive and most negative review\n",
                "probabilities = sentiment_model.predict_proba(validation_data[features])\n",
                "positive_index = probabilities[:, 1].argmax()\n",
                "negative_index = probabilities[:, 0].argmax()\n",
                "\n",
                "most_positive_review = validation_data.iloc[positive_index]['review_clean']\n",
                "most_negative_review = validation_data.iloc[negative_index]['review_clean']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Most Positive Review:\nI have been on an organic foods diet for almost a year now and I have become much more sensitive to what I eat and drink Out are the energy drinks loaded with sugars caffeine and artificial ingredients In are the more gentler and natural energy boosters This was  a surprise for me I really liked it and it did give an energy boost without any late energy crashesThe flavor is nice A good palatable taste and feel in the mouth No bad after taste It sits well on the stomach even an empty one It provides and fairly quick ramp up in energy and alertness and lasts for several hours to all day The ramp down in gently and hardly noticeable I like the ingredients and the overall effectI am finding that I need less energy boosting as my diet is becoming cleaner and healthier However I am going to rely on these until the day when I can maintain great energy levels without supports Or at least keeps a few in the fridge for special occasions 5 Stars easy Hope you get as much out of it as I have\n\nMost Negative Review:\nThe Chocolate Espresso flavor of the thinkThin bars is the only one I have tasted and I found it disappointing  There was no coffee flavor to the bar other than bitterness  Is that supposed to be the espresso flavor  I have tasted many other things with a better coffee flavor  The chocolate flavor is strong but more of a baking chocolate flavor not candy flavor  Of course since the bar contains zero sugar barely any fat and is gluten free it isnt going to have a rich flavor to it It contains 20 grams of protein but only 10 Calcium and 15 Iron for the RDA  It leaves a strong after taste that made me grab for a beverage to get rid of it  If you like a bitter chocolate flavor then you would like this bar  Personally I wont be eating another of this flavor\n"
                }
            ],
            "source": [
                "print('Most Positive Review:')\n",
                "print(most_positive_review)\n",
                "print()\n",
                "print('Most Negative Review:')\n",
                "print(most_negative_review)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Do you notice something special about those reviews? They are both pretty long! Here we just count number of words regardless of the length of the review, but clearly that can affect the results. In practice, one can use some techniques to normalize the counts to avoid prioritizing long reviews over shorter ones (we will discuss this idea in a future week).\n",
                "\n",
                "### **Question 4:** Compute validation accuracy\n",
                "Compute the validation accuracy for the model we just trained. Report the validation accuracy as a number between 0 and 1 stored in a variable called `sentiment_model_validation_accuracy`.\n",
                "\n",
                "Below, calculate the accuracy of the predictor using sklearn's [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. Note that you should use the **predicted labels**, not the predicted probabilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q4_sentiment_model_accuracy) ###\n",
                "\n",
                "# TODO Find the validation accuracy of the sentiment model\n",
                "predicted_labels = sentiment_model.predict(validation_data[features])\n",
                "sentiment_model_validation_accuracy = accuracy_score(validation_data['sentiment'], predicted_labels)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create a confusion matrix\n",
                "\n",
                "A common tool used when analyzing the peformance of a predictor in a classification problem is to look at the confusion matrix, as well as the overall accuracy.\n",
                "\n",
                "We've created a function that will plot a confusion matrix for you given a set of inputs which are the values that should appear within each cell.\n",
                "Recall that there are four values associated with a confusion matrix: true positive, true negative, false positive, and false negative which we will abberviate as TP, TN, FP, and FN, respecitvely. In other words, for the next problem we have handled the plotting code for you that you can use, but you will need to compute the values for each of the confusion matrix dimensions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(tp, fp, fn, tn):\n",
                "    \"\"\"\n",
                "    Plots a confusion matrix using the values \n",
                "       tp - True Positive\n",
                "       fp - False Positive\n",
                "       fn - False Negative\n",
                "       tn - True Negative\n",
                "    \"\"\"\n",
                "    data = np.matrix([[tp, fp], [fn, tn]])\n",
                "\n",
                "    sns.heatmap(data,annot=True,xticklabels=['Actual Pos', 'Actual Neg']\n",
                "              ,yticklabels=['Pred. Pos', 'Pred. Neg']) "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Question 5:** Compute confusion matrix values and plot\n",
                "\n",
                "Write code below that uses the `plot_confusion_matrix` function to show the number of true positive, true negative, false positive, and false negative predictions made by your classifier on the validation set. You should store the counts for each of these values in the variables:\n",
                "* `tp`\n",
                "* `fp`\n",
                "* `fn`\n",
                "* `tn` \n",
                "\n",
                "You might find it useful to use named parameters here (i.e. you can call `plot_confusion_matrix(tp=X, fp=Y, fn=A, tn=B)` instead of having to get the order of the parameters correct).\n",
                "\n",
                "There are multiple ways to solve this. One involves iterating over every datapoint and comparing its prediction to the actual; another involves using [sklearn's confusion_matrix function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) (see the examples for an example of using that function for binary classification)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q5_confusion_matrix) ###\n",
                "\n",
                "# TODO Compute the four values tp, fp, fn, tn and plot them using plot_confusion_matrix\n",
                "from sklearn.metrics import confusion_matrix\n",
                "tp = None\n",
                "fp = None\n",
                "tn = None\n",
                "fn = None\n",
                "tn, fp, fn, tp = confusion_matrix(validation_data['sentiment'], predicted_labels).ravel()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": "\u003cFigure size 640x480 with 2 Axes\u003e"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plot_confusion_matrix(tp=tp, fp=fp, tn=tn, fn=fn)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Question 6 and 7**: Logistic Regression with L2 regularization\n",
                "\n",
                "One of the challenges of creating features from each word is that there are many more features than observations. It is easy to overfit. We will explore the effect of the regularization in this problem.\n",
                "\n",
                "Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. \n",
                "\n",
                "Like in the last assignment, we will train models with various levels of regularization starting with a small amount and then moving to a  large amount. The code here will have some similarities to the code you did in the last assignment, so you will find that to be a useful reference, but this problem will be slightly more complex since we ask you to compute a few values.\n",
                "\n",
                "This code will be counted as two separate questions since you will be computing slightly different values, but we will ask you to compute both of them in the same starter code to reduce code duplication (since the tasks are very similar). \n",
                "\n",
                "We first outline what you should compute for each question and then show some general implementation notes for both problems below. Your task for this problem is to fill out the code inside the loop to compute the values described below.\n",
                "\n",
                "\u003cspan style=\"color: green;\"\u003eTip!\u003c/span\u003e We recommend focusing on the values you need to compute for Q6 and then once you have that working work on the code you need to compute Q7.\n",
                "\n",
                "### **Question 6:** Coefficient Paths\n",
                "For this question we will ask you to compute the coefficent path for each of the features in the model for various values of the regularization constant.\n",
                "\n",
                "For each regularization strength, train a model using that regularization constant and create a table storing the coefficients of each learned predictor. Store the results in a `DataFrame` named `coef_table`.\n",
                "\n",
                "You should end up with an `DataFrame` with column names as `'coefficients [L2=1e-02]', ... 'coefficients [L2=1e+05]'`, and a row for each word in `features`. It should look something like the following:\n",
                "\n",
                "|     | word | coefficients [L2=1e-02] | coefficients [L2=1e+00] | ... | coefficients [L2=1e+05] |\n",
                "|-----|------|-------------------------|-------------------------|-----|-------------------------|\n",
                "| 0   |  word1 |           ...           |           ...           | ... |           ...           |\n",
                "| 1   |  word2 |           ...           |           ...           | ... |           ...           |\n",
                "| ... |  ..  |           ...           |           ...           | ... |           ...           |\n",
                "\n",
                "Before the loop, we set up `coef_table` to have the right rows and columns, but your code will need to fill out the rest.\n",
                "\n",
                "### **Question 7:** Train and Validation Accuracies\n",
                "Similar to Q6, we want you to compute the training and validation accuracy for each learned predictor and store that in a `DataFrame` called `accuracies_table`. \n",
                "\n",
                "You should end up with a `DataFrame` with column names `'l2_penalty', 'train_accuracy', 'validation_accuracy'` and a row for each L2 penalty tried. The L2 penaly should be the number (not the column name from Q7) and the accuracy values should be numbers between 0 and 1 for the appropriate accuracy. It should look something like the following:\n",
                "\n",
                "|     | l2_penalty | train_accuracy | validation_accuracy |\n",
                "|-----|------------|----------------|---------------------|\n",
                "| 0   |    0.01    |       ...      |         ...         |\n",
                "| 1   |      1     |       ...      |         ...         |\n",
                "| ... |     ..     |       ...      |         ...         |\n",
                "\n",
                "For this problem, we recommend the approach used in HW1 to build up a list of dictionaries, and then convert that to a `DataFrame` with the values described.\n",
                "\n",
                "### Implementation Details\n",
                "\n",
                "Some important notes about your implementation:\n",
                "*  When constructing a `LogisticRegression` object, make sure to use `random_state=1` to get the same results as us. We also want to avoid having an intercept term in this example, so also pass `fit_intercept=False` when constructing the `LogisticRegression` model.\n",
                "* \u003cspan style=\"color:red\"\u003eWhen constructing the LogisticRegression(...) model, the parameter `C` is the **inverse** of $\\lambda$ (i.e., $C=\\frac{1}{\\lambda}$). \u003c/span\u003e\n",
                "* Q7: To store the results of your predictor's coefficients, you will need to get the values from the `.coef_` property. Since the code for this is a little complex, we give you this line below (assumes your trained model is stored in a variable called `model`):\n",
                "  ```\n",
                "  coef_table[column_name] = model.coef_[0]\n",
                "  ```\n",
                "\n",
                "* It is okay if your code prints `ConvergenceWarnings`. This is something you would want to avoid in practice but is okay in our assignment for simplicity.\n",
                "\n",
                "* We recommend just focusing on Q6 at first and getting the code to set up the coefficients table right. Then once that's working, evaluate the models for Q7.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q6_q7_train_models) ###\n",
                "\n",
                "# TODO Fill in the loop below\n",
                "\n",
                "# Set up the regularization penalities to try\n",
                "l2_penalties = [0.01, 1, 4, 10, 1e2, 1e3, 1e5]\n",
                "l2_penalty_names = [f'coefficients [L2={l2_penalty:.0e}]' \n",
                "                    for l2_penalty in l2_penalties]\n",
                "\n",
                "# Q6: Add the coefficients to this coef_table for each model\n",
                "coef_table = pd.DataFrame(columns=['word'] + l2_penalty_names)\n",
                "coef_table['word'] = features\n",
                "\n",
                "# Q7: Set up an empty list to store the accuracies (will convert to DataFrame after loop)\n",
                "accuracy_data = []\n",
                "\n",
                "for l2_penalty, l2_penalty_column_name in zip(l2_penalties, l2_penalty_names):\n",
                "    # TODO(Q6 and Q7): Train the model. Remember to pass `fit_intercept=False` and `random_state=1` to the model.\n",
                "    clf = LogisticRegression(penalty = 'l2', C = 1/l2_penalty,fit_intercept=False, random_state=1\n",
                "                    ).fit(train_data[features], train_data['sentiment'])\n",
                "    # TODO(Q6): Save the coefficients in coef_table\n",
                "    coef_table[l2_penalty_column_name] = clf.coef_[0]\n",
                "    # TODO(Q7): Calculate and save the train and validation accuracies\n",
                "    valid_acc = accuracy_score(validation_data['sentiment'], clf.predict(validation_data[features]))\n",
                "    train_acc = accuracy_score(train_data['sentiment'], clf.predict(train_data[features]))\n",
                "    accuracy_data.append({'l2_penalty': l2_penalty, 'train_accuracy': train_acc, 'validation_accuracy': valid_acc})\n",
                "    \n",
                "accuracies_table = pd.DataFrame(accuracy_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eword\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=1e-02]\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=1e+00]\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=4e+00]\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=1e+01]\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=1e+02]\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=1e+03]\u003c/th\u003e\n      \u003cth\u003ecoefficients [L2=1e+05]\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e0000\u003c/td\u003e\n      \u003ctd\u003e0.107215\u003c/td\u003e\n      \u003ctd\u003e0.030762\u003c/td\u003e\n      \u003ctd\u003e0.017188\u003c/td\u003e\n      \u003ctd\u003e0.010918\u003c/td\u003e\n      \u003ctd\u003e0.002989\u003c/td\u003e\n      \u003ctd\u003e0.000476\u003c/td\u003e\n      \u003ctd\u003e5.045637e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e002\u003c/td\u003e\n      \u003ctd\u003e-0.019075\u003c/td\u003e\n      \u003ctd\u003e-0.001973\u003c/td\u003e\n      \u003ctd\u003e-0.002153\u003c/td\u003e\n      \u003ctd\u003e-0.001966\u003c/td\u003e\n      \u003ctd\u003e-0.000746\u003c/td\u003e\n      \u003ctd\u003e-0.000099\u003c/td\u003e\n      \u003ctd\u003e-4.085575e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e004\u003c/td\u003e\n      \u003ctd\u003e-0.019075\u003c/td\u003e\n      \u003ctd\u003e-0.001973\u003c/td\u003e\n      \u003ctd\u003e-0.002153\u003c/td\u003e\n      \u003ctd\u003e-0.001966\u003c/td\u003e\n      \u003ctd\u003e-0.000746\u003c/td\u003e\n      \u003ctd\u003e-0.000099\u003c/td\u003e\n      \u003ctd\u003e-4.085575e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e004oz\u003c/td\u003e\n      \u003ctd\u003e-0.019075\u003c/td\u003e\n      \u003ctd\u003e-0.001973\u003c/td\u003e\n      \u003ctd\u003e-0.002153\u003c/td\u003e\n      \u003ctd\u003e-0.001966\u003c/td\u003e\n      \u003ctd\u003e-0.000746\u003c/td\u003e\n      \u003ctd\u003e-0.000099\u003c/td\u003e\n      \u003ctd\u003e-4.085575e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e012months\u003c/td\u003e\n      \u003ctd\u003e0.032081\u003c/td\u003e\n      \u003ctd\u003e0.001532\u003c/td\u003e\n      \u003ctd\u003e0.001615\u003c/td\u003e\n      \u003ctd\u003e0.001501\u003c/td\u003e\n      \u003ctd\u003e0.001130\u003c/td\u003e\n      \u003ctd\u003e0.000399\u003c/td\u003e\n      \u003ctd\u003e5.049857e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e7620\u003c/th\u003e\n      \u003ctd\u003ezicos\u003c/td\u003e\n      \u003ctd\u003e-0.131704\u003c/td\u003e\n      \u003ctd\u003e-0.055637\u003c/td\u003e\n      \u003ctd\u003e-0.030848\u003c/td\u003e\n      \u003ctd\u003e-0.018653\u003c/td\u003e\n      \u003ctd\u003e-0.003718\u003c/td\u003e\n      \u003ctd\u003e-0.000447\u003c/td\u003e\n      \u003ctd\u003e-4.923324e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e7621\u003c/th\u003e\n      \u003ctd\u003ezillion\u003c/td\u003e\n      \u003ctd\u003e-0.073327\u003c/td\u003e\n      \u003ctd\u003e-0.037442\u003c/td\u003e\n      \u003ctd\u003e-0.029708\u003c/td\u003e\n      \u003ctd\u003e-0.020870\u003c/td\u003e\n      \u003ctd\u003e-0.004020\u003c/td\u003e\n      \u003ctd\u003e-0.000466\u003c/td\u003e\n      \u003ctd\u003e-4.973674e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e7622\u003c/th\u003e\n      \u003ctd\u003ezinger\u003c/td\u003e\n      \u003ctd\u003e-0.029916\u003c/td\u003e\n      \u003ctd\u003e-0.003715\u003c/td\u003e\n      \u003ctd\u003e-0.004730\u003c/td\u003e\n      \u003ctd\u003e-0.004572\u003c/td\u003e\n      \u003ctd\u003e-0.002496\u003c/td\u003e\n      \u003ctd\u003e-0.000412\u003c/td\u003e\n      \u003ctd\u003e-4.893557e-06\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e7623\u003c/th\u003e\n      \u003ctd\u003ezip\u003c/td\u003e\n      \u003ctd\u003e0.111437\u003c/td\u003e\n      \u003ctd\u003e0.051768\u003c/td\u003e\n      \u003ctd\u003e0.033141\u003c/td\u003e\n      \u003ctd\u003e0.022192\u003c/td\u003e\n      \u003ctd\u003e0.005980\u003c/td\u003e\n      \u003ctd\u003e0.001038\u003c/td\u003e\n      \u003ctd\u003e1.027987e-05\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e7624\u003c/th\u003e\n      \u003ctd\u003eziplock\u003c/td\u003e\n      \u003ctd\u003e0.085013\u003c/td\u003e\n      \u003ctd\u003e0.035280\u003c/td\u003e\n      \u003ctd\u003e0.020182\u003c/td\u003e\n      \u003ctd\u003e0.012145\u003c/td\u003e\n      \u003ctd\u003e0.002320\u003c/td\u003e\n      \u003ctd\u003e0.000227\u003c/td\u003e\n      \u003ctd\u003e2.699920e-07\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e7625 rows Ã 8 columns\u003c/p\u003e\n\u003c/div\u003e",
                        "text/plain": "           word  coefficients [L2=1e-02]  coefficients [L2=1e+00]  \\\n0          0000                 0.107215                 0.030762   \n1           002                -0.019075                -0.001973   \n2           004                -0.019075                -0.001973   \n3         004oz                -0.019075                -0.001973   \n4     012months                 0.032081                 0.001532   \n...         ...                      ...                      ...   \n7620      zicos                -0.131704                -0.055637   \n7621    zillion                -0.073327                -0.037442   \n7622     zinger                -0.029916                -0.003715   \n7623        zip                 0.111437                 0.051768   \n7624    ziplock                 0.085013                 0.035280   \n\n      coefficients [L2=4e+00]  coefficients [L2=1e+01]  \\\n0                    0.017188                 0.010918   \n1                   -0.002153                -0.001966   \n2                   -0.002153                -0.001966   \n3                   -0.002153                -0.001966   \n4                    0.001615                 0.001501   \n...                       ...                      ...   \n7620                -0.030848                -0.018653   \n7621                -0.029708                -0.020870   \n7622                -0.004730                -0.004572   \n7623                 0.033141                 0.022192   \n7624                 0.020182                 0.012145   \n\n      coefficients [L2=1e+02]  coefficients [L2=1e+03]  \\\n0                    0.002989                 0.000476   \n1                   -0.000746                -0.000099   \n2                   -0.000746                -0.000099   \n3                   -0.000746                -0.000099   \n4                    0.001130                 0.000399   \n...                       ...                      ...   \n7620                -0.003718                -0.000447   \n7621                -0.004020                -0.000466   \n7622                -0.002496                -0.000412   \n7623                 0.005980                 0.001038   \n7624                 0.002320                 0.000227   \n\n      coefficients [L2=1e+05]  \n0                5.045637e-06  \n1               -4.085575e-06  \n2               -4.085575e-06  \n3               -4.085575e-06  \n4                5.049857e-06  \n...                       ...  \n7620            -4.923324e-06  \n7621            -4.973674e-06  \n7622            -4.893557e-06  \n7623             1.027987e-05  \n7624             2.699920e-07  \n\n[7625 rows x 8 columns]"
                    },
                    "execution_count": 155,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Look at coef_table\n",
                "coef_table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003el2_penalty\u003c/th\u003e\n      \u003cth\u003etrain_accuracy\u003c/th\u003e\n      \u003cth\u003evalidation_accuracy\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e0.01\u003c/td\u003e\n      \u003ctd\u003e1.000000\u003c/td\u003e\n      \u003ctd\u003e0.651685\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e1.00\u003c/td\u003e\n      \u003ctd\u003e0.998594\u003c/td\u003e\n      \u003ctd\u003e0.685393\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e4.00\u003c/td\u003e\n      \u003ctd\u003e0.995781\u003c/td\u003e\n      \u003ctd\u003e0.685393\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e10.00\u003c/td\u003e\n      \u003ctd\u003e0.976090\u003c/td\u003e\n      \u003ctd\u003e0.696629\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e100.00\u003c/td\u003e\n      \u003ctd\u003e0.895921\u003c/td\u003e\n      \u003ctd\u003e0.719101\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e5\u003c/th\u003e\n      \u003ctd\u003e1000.00\u003c/td\u003e\n      \u003ctd\u003e0.734177\u003c/td\u003e\n      \u003ctd\u003e0.674157\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e6\u003c/th\u003e\n      \u003ctd\u003e100000.00\u003c/td\u003e\n      \u003ctd\u003e0.502110\u003c/td\u003e\n      \u003ctd\u003e0.516854\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e",
                        "text/plain": "   l2_penalty  train_accuracy  validation_accuracy\n0        0.01        1.000000             0.651685\n1        1.00        0.998594             0.685393\n2        4.00        0.995781             0.685393\n3       10.00        0.976090             0.696629\n4      100.00        0.895921             0.719101\n5     1000.00        0.734177             0.674157\n6   100000.00        0.502110             0.516854"
                    },
                    "execution_count": 156,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Look at accuracies_table\n",
                "accuracies_table"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Question 8:** Inspect Coefficients\n",
                "\n",
                "We'll now look at the **coefficients** for the model that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
                "\n",
                "Using **the coefficients trained with L2 penalty 1**, find the 5 most positive words (with largest positive coefficients). Save them to `positive_words`. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to `negative_words`. The result should be the `'word'` column for the these rows. \n",
                "\n",
                "To be specific, the type of the value we are looking for is a `Series` in `pandas` which is the type of a single row or column in a `DataFrame`. When you have a `DataFrame`, it is a structure with rows and columns. When you access a single column as in `df[column_name]`, this returns a `Series` representing that one column. \n",
                "\n",
                "This means your result for each one of these variables should be a `Series` of length 5 for the respective words.\n",
                "\n",
                "\n",
                "*Hint:* You can use the `.nlargest()` and `.nsmallest()` method on an DataFrame to find the top `n` rows sorted according to the value of a specified column. Here is the documentation for [nlargest](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 167,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_q8_most_positive_negative) ###\n",
                "\n",
                "\n",
                "# TODO Compute words with the 5 largest coefficients and 5 smallest coefficients\n",
                "sorted_coef = coef_table.sort_values(by=['coefficients [L2=1e+00]'])\n",
                "positive_words = sorted_coef.tail(5)['word'].iloc[::-1]\n",
                "negative_words = sorted_coef.head(5)['word']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "1925       days\n3037       good\n4981    perfect\n863        best\n3096      great\nName: word, dtype: object\n4586          not\n1398    chocolate\n6862      thought\n919         bland\n4177          may\nName: word, dtype: object\n"
                }
            ],
            "source": [
                "print(positive_words)\n",
                "print(negative_words)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us observe the effect of increasing L2 penalty on the 10 words just selected. We provide you with a utility function to  plot the coefficient path."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": "\u003cFigure size 1000x600 with 1 Axes\u003e"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "TypeError",
                    "evalue": "only list-like objects are allowed to be passed to isin(), you passed a [NoneType]",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoefficient value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_xscale(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---\u003e 49\u001b[0m \u001b[43mmake_coefficient_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoef_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_penalty_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_penalties\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mmake_coefficient_plot\u001b[0;34m(table, positive_words, negative_words, l2_penalty_list)\u001b[0m\n\u001b[1;32m     36\u001b[0m cmap_positive \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m cmap_negative \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mget_cmap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---\u003e 38\u001b[0m \u001b[43mplot_coeffs_for_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap_positive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m plot_coeffs_for_words(ax, negative_words, cmap_negative)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Set up axis labels, scale, and legend  \u001b[39;00m\n",
                        "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mmake_coefficient_plot.\u003clocals\u003e.plot_coeffs_for_words\u001b[0;34m(ax, words, cmap)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_coeffs_for_words\u001b[39m(ax, words, cmap):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Given an axes to plot on and a list of words and a cmap,\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    plots the coefficient paths for each word in words\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---\u003e 20\u001b[0m     words_df \u001b[38;5;241m=\u001b[39m table[\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     21\u001b[0m     words_df \u001b[38;5;241m=\u001b[39m words_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# To make indices sequential\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m words_df\u001b[38;5;241m.\u001b[39miterrows():\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/series.py:5563\u001b[0m, in \u001b[0;36mSeries.isin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   5490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misin\u001b[39m(\u001b[38;5;28mself\u001b[39m, values) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m\u003e\u001b[39m Series:\n\u001b[1;32m   5491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5492\u001b[0m \u001b[38;5;124;03m    Whether elements in Series are contained in `values`.\u001b[39;00m\n\u001b[1;32m   5493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5561\u001b[0m \u001b[38;5;124;03m    dtype: bool\u001b[39;00m\n\u001b[1;32m   5562\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-\u003e 5563\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   5565\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5566\u001b[0m     )\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/algorithms.py:459\u001b[0m, in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly list-like objects are allowed to be passed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto isin(), you passed a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(comps)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m     )\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(values):\n\u001b[0;32m--\u003e 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly list-like objects are allowed to be passed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto isin(), you passed a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (ABCIndex, ABCSeries, ABCExtensionArray, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m    465\u001b[0m     orig_values \u001b[38;5;241m=\u001b[39m values\n",
                        "\u001b[0;31mTypeError\u001b[0m: only list-like objects are allowed to be passed to isin(), you passed a [NoneType]"
                    ]
                }
            ],
            "source": [
                "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
                "    \"\"\"\n",
                "    Makes a plot of coefficients, given a table where rows correspond to words and\n",
                "    columns correspond to the l2 penalty, a list of positive words, a list of \n",
                "    negative words, and a list of l2 penalties.\n",
                "    \"\"\"\n",
                "    def get_cmap_value(cmap, i, total_words):\n",
                "        \"\"\"\n",
                "        Computes a nice scaling of from i=0 to i=total_words - 1\n",
                "        for the given cmap\n",
                "        \"\"\"\n",
                "        return cmap(0.8 * ((i + 1) / (total_words * 1.2) + 0.15))\n",
                "\n",
                "\n",
                "    def plot_coeffs_for_words(ax, words, cmap):\n",
                "        \"\"\"\n",
                "        Given an axes to plot on and a list of words and a cmap,\n",
                "        plots the coefficient paths for each word in words\n",
                "        \"\"\"\n",
                "        words_df = table[table['word'].isin(words)]\n",
                "        words_df = words_df.reset_index(drop=True)  # To make indices sequential\n",
                "\n",
                "        for i, row in words_df.iterrows():\n",
                "            color = get_cmap_value(cmap, i, len(words))\n",
                "            ax.plot(xx, row[row.index != 'word'], '-',\n",
                "                    label=row['word'], linewidth=4.0, color=color)\n",
                "\n",
                "    # Make a canvas to draw on\n",
                "    fig, ax = plt.subplots(1, figsize=(10, 6))\n",
                "   \n",
                "    # Set up the xs to plot and draw a line for y=0\n",
                "    xx = l2_penalty_list\n",
                "    ax.plot(xx, [0.] * len(xx), '--', linewidth=1, color='k')\n",
                "\n",
                "    # Plot the positive and negative coefficient paths\n",
                "    cmap_positive = plt.get_cmap('Reds')\n",
                "    cmap_negative = plt.get_cmap('Blues')\n",
                "    plot_coeffs_for_words(ax, positive_words, cmap_positive)\n",
                "    plot_coeffs_for_words(ax, negative_words, cmap_negative)\n",
                "\n",
                "    # Set up axis labels, scale, and legend  \n",
                "    ax.legend(loc='best', ncol=2, prop={'size':16}, columnspacing=0.5 )\n",
                "    ax.set_title('Coefficient path')\n",
                "    ax.set_xlabel('L2 penalty ($\\lambda$)')\n",
                "    ax.set_ylabel('Coefficient value')\n",
                "    ax.set_xscale('log')\n",
                "\n",
                "\n",
                "make_coefficient_plot(coef_table, positive_words, negative_words, l2_penalty_list=l2_penalties)"
            ]
        }
    ]
}
